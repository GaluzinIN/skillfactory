{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math\nfrom sklearn.model_selection import GridSearchCV\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-23T13:56:34.582949Z","iopub.execute_input":"2022-02-23T13:56:34.583251Z","iopub.status.idle":"2022-02-23T13:56:34.599289Z","shell.execute_reply.started":"2022-02-23T13:56:34.583215Z","shell.execute_reply":"2022-02-23T13:56:34.598294Z"},"trusted":true},"execution_count":709,"outputs":[]},{"cell_type":"markdown","source":"План работы:\n1. Изучить базовый код:\n    В базовом коде имеем:\n    1.1. Тренировочный и тестовый датасеты помечены с учетом того чтобы в последствии их разъеденить обратно. Затем они слиты в единый датасет чтобы подвергнуться предобработке.\n    1.2. Обработаны бинарные переменные\n    1.3. Обработаны категорийные переменные\n    1.4. Обратное разделение на тренировочный и тестовый датасеты\n    1.5. Разделение тренировочного датасета на обучающий и валидационный датасеты.\n    1.6. Обучение модели\n    1.7. Вывод метрик\n2. Провести EDA:\n3. Предобработка:\n4. Добавить дополнительные признаки\n5. Обучение модели \n6. Оценка модели\n7. Рефлексия над проектом.","metadata":{}},{"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-scoring/'\ndf_train = pd.read_csv(DATA_DIR +'/train.csv')\ndf_test = pd.read_csv(DATA_DIR +'/test.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:34.601005Z","iopub.execute_input":"2022-02-23T13:56:34.601406Z","iopub.status.idle":"2022-02-23T13:56:34.748796Z","shell.execute_reply.started":"2022-02-23T13:56:34.601377Z","shell.execute_reply":"2022-02-23T13:56:34.747228Z"},"trusted":true},"execution_count":710,"outputs":[]},{"cell_type":"code","source":"sample_submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:34.750131Z","iopub.execute_input":"2022-02-23T13:56:34.750350Z","iopub.status.idle":"2022-02-23T13:56:34.756444Z","shell.execute_reply.started":"2022-02-23T13:56:34.750322Z","shell.execute_reply":"2022-02-23T13:56:34.755592Z"},"trusted":true},"execution_count":711,"outputs":[]},{"cell_type":"code","source":"df_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:34.757738Z","iopub.execute_input":"2022-02-23T13:56:34.758122Z","iopub.status.idle":"2022-02-23T13:56:34.772587Z","shell.execute_reply.started":"2022-02-23T13:56:34.758093Z","shell.execute_reply":"2022-02-23T13:56:34.771775Z"},"trusted":true},"execution_count":712,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:34.775083Z","iopub.execute_input":"2022-02-23T13:56:34.775446Z","iopub.status.idle":"2022-02-23T13:56:34.814823Z","shell.execute_reply.started":"2022-02-23T13:56:34.775416Z","shell.execute_reply":"2022-02-23T13:56:34.814297Z"},"trusted":true},"execution_count":713,"outputs":[]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:34.815825Z","iopub.execute_input":"2022-02-23T13:56:34.816594Z","iopub.status.idle":"2022-02-23T13:56:34.836454Z","shell.execute_reply.started":"2022-02-23T13:56:34.816521Z","shell.execute_reply":"2022-02-23T13:56:34.835875Z"},"trusted":true},"execution_count":714,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:34.837581Z","iopub.execute_input":"2022-02-23T13:56:34.837908Z","iopub.status.idle":"2022-02-23T13:56:34.881447Z","shell.execute_reply.started":"2022-02-23T13:56:34.837866Z","shell.execute_reply":"2022-02-23T13:56:34.880846Z"},"trusted":true},"execution_count":715,"outputs":[]},{"cell_type":"code","source":"sample_submission.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:34.882629Z","iopub.execute_input":"2022-02-23T13:56:34.882987Z","iopub.status.idle":"2022-02-23T13:56:34.890782Z","shell.execute_reply.started":"2022-02-23T13:56:34.882952Z","shell.execute_reply":"2022-02-23T13:56:34.890205Z"},"trusted":true},"execution_count":716,"outputs":[]},{"cell_type":"code","source":"sample_submission.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:34.891872Z","iopub.execute_input":"2022-02-23T13:56:34.892200Z","iopub.status.idle":"2022-02-23T13:56:34.917378Z","shell.execute_reply.started":"2022-02-23T13:56:34.892171Z","shell.execute_reply":"2022-02-23T13:56:34.916436Z"},"trusted":true},"execution_count":717,"outputs":[]},{"cell_type":"code","source":"# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0  # помечаем где у нас тест\ndf_test['default'] = 0 # в тесте у нас нет значения default, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:34.919129Z","iopub.execute_input":"2022-02-23T13:56:34.919373Z","iopub.status.idle":"2022-02-23T13:56:34.965674Z","shell.execute_reply.started":"2022-02-23T13:56:34.919340Z","shell.execute_reply":"2022-02-23T13:56:34.964310Z"},"trusted":true},"execution_count":718,"outputs":[]},{"cell_type":"code","source":"data.nunique(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:34.967620Z","iopub.execute_input":"2022-02-23T13:56:34.968460Z","iopub.status.idle":"2022-02-23T13:56:35.026965Z","shell.execute_reply.started":"2022-02-23T13:56:34.968425Z","shell.execute_reply":"2022-02-23T13:56:35.026166Z"},"trusted":true},"execution_count":719,"outputs":[]},{"cell_type":"code","source":"num_cols = ['age', 'score_bki', 'decline_app_cnt', 'bki_request_cnt', 'income']\ncat_cols = ['education', 'first_time', 'sna', 'work_address', 'home_address', 'region_rating']\nbin_cols = ['sex', 'car', 'car_type', 'good_work', 'foreign_passport']","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:35.028035Z","iopub.execute_input":"2022-02-23T13:56:35.028205Z","iopub.status.idle":"2022-02-23T13:56:35.033469Z","shell.execute_reply.started":"2022-02-23T13:56:35.028182Z","shell.execute_reply":"2022-02-23T13:56:35.032069Z"},"trusted":true},"execution_count":720,"outputs":[]},{"cell_type":"code","source":"print(data.default.value_counts())\ndata.score_bki.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:35.035009Z","iopub.execute_input":"2022-02-23T13:56:35.035290Z","iopub.status.idle":"2022-02-23T13:56:35.059471Z","shell.execute_reply.started":"2022-02-23T13:56:35.035252Z","shell.execute_reply":"2022-02-23T13:56:35.058627Z"},"trusted":true},"execution_count":721,"outputs":[]},{"cell_type":"code","source":"data['default'].value_counts(ascending=True).plot(kind='barh')","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:35.063426Z","iopub.execute_input":"2022-02-23T13:56:35.063723Z","iopub.status.idle":"2022-02-23T13:56:35.285170Z","shell.execute_reply.started":"2022-02-23T13:56:35.063689Z","shell.execute_reply":"2022-02-23T13:56:35.284383Z"},"trusted":true},"execution_count":722,"outputs":[]},{"cell_type":"code","source":"# Удаляем столбцы которые бесполезные для обучения модели\ndata.drop(['client_id','app_date',], axis = 1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:35.286248Z","iopub.execute_input":"2022-02-23T13:56:35.286461Z","iopub.status.idle":"2022-02-23T13:56:35.299949Z","shell.execute_reply.started":"2022-02-23T13:56:35.286432Z","shell.execute_reply":"2022-02-23T13:56:35.299164Z"},"trusted":true},"execution_count":723,"outputs":[]},{"cell_type":"code","source":"# посмотрим на распределение числовых признаков\nfor i in num_cols:\n    plt.figure()\n    sns.distplot(data[i][data[i] > 0].dropna(), kde = False, rug=False)\n    plt.title(i)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:35.301021Z","iopub.execute_input":"2022-02-23T13:56:35.301274Z","iopub.status.idle":"2022-02-23T13:56:36.810205Z","shell.execute_reply.started":"2022-02-23T13:56:35.301251Z","shell.execute_reply":"2022-02-23T13:56:36.808725Z"},"trusted":true},"execution_count":724,"outputs":[]},{"cell_type":"code","source":"# Из графиков видим что первое это что наши числовые значения сильно несбалансированы\n# по абсолютным значениям. Второе что имеются многочисленные выбросы. \n# Для исправления воспользуемся RobustScaler после того как разделим на обучающую выборку и\n# валидационную. Сразу на всем датасете делать нельзя так как модель будет подстраиваться под тестовую часть\n\nsns.set_theme(style=\"whitegrid\")\nax = sns.boxplot(data=data[num_cols])","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:36.811812Z","iopub.execute_input":"2022-02-23T13:56:36.812143Z","iopub.status.idle":"2022-02-23T13:56:37.216427Z","shell.execute_reply.started":"2022-02-23T13:56:36.812101Z","shell.execute_reply":"2022-02-23T13:56:37.215595Z"},"trusted":true},"execution_count":725,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Выводим корреляционную матрицу, видим что наши числовые признаки имееют слабую \n# линейную корреляцию между собой и проредить столбцы с высокой кореляцией нет вариантов.\nsns.heatmap(data[num_cols].corr().abs(), vmin=0, vmax=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:37.218139Z","iopub.execute_input":"2022-02-23T13:56:37.218467Z","iopub.status.idle":"2022-02-23T13:56:37.561050Z","shell.execute_reply.started":"2022-02-23T13:56:37.218428Z","shell.execute_reply":"2022-02-23T13:56:37.560134Z"},"trusted":true},"execution_count":726,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Обрабатываем категорийные признаки\ndata = pd.get_dummies(data, columns=['education'], dummy_na=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:37.562483Z","iopub.execute_input":"2022-02-23T13:56:37.562931Z","iopub.status.idle":"2022-02-23T13:56:37.609187Z","shell.execute_reply.started":"2022-02-23T13:56:37.562893Z","shell.execute_reply":"2022-02-23T13:56:37.607859Z"},"trusted":true},"execution_count":727,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nfor column in bin_cols:\n    data[column] = le.fit_transform(data[column])\n    \ncolumns = ['first_time', 'sna', 'work_address', 'home_address', 'region_rating']\n\nfor column in columns:\n    data[column] = le.fit_transform(data[column])","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:37.610310Z","iopub.execute_input":"2022-02-23T13:56:37.610848Z","iopub.status.idle":"2022-02-23T13:56:37.724653Z","shell.execute_reply.started":"2022-02-23T13:56:37.610819Z","shell.execute_reply":"2022-02-23T13:56:37.723647Z"},"trusted":true},"execution_count":728,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:37.725878Z","iopub.execute_input":"2022-02-23T13:56:37.726097Z","iopub.status.idle":"2022-02-23T13:56:37.744144Z","shell.execute_reply.started":"2022-02-23T13:56:37.726068Z","shell.execute_reply":"2022-02-23T13:56:37.743456Z"},"trusted":true},"execution_count":729,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = data.query('sample == 1').drop(['sample'], axis=1)\ntest_data = data.query('sample == 0').drop(['sample', 'default'], axis=1)\n\n# Уменьшаем количество доминирующего класса путем отрезания n-первых строк, где n количество примеров класса меньшинства\nn = train_data.default.value_counts()[1]\nvis_data_1 = train_data[(train_data.default == 1)]\nvis_data_plus = train_data[(train_data.default == 0)].iloc[0:n]\ndf = pd.concat([vis_data_plus, vis_data_1], axis=0, ignore_index=True)\n\n# Увеличиваем количество записей класса меньшинства путем n-раз добавления \n#n = train_data.default.value_counts()[1]\n#m = train_data.default.value_counts()[0]\n#l = m // n\n#vis_data_1 = train_data[(train_data.default == 1)]\n#vis_data_plus = train_data[(train_data.default == 0)]\n#vis_data_2 = pd.concat([vis_data_1, vis_data_1], axis=0, ignore_index=True)\n#for i in range(l-1):\n#    vis_data_2 = pd.concat([vis_data_2, vis_data_1], axis=0, ignore_index=True)\n#df = pd.concat([vis_data_plus, vis_data_2], axis=0, ignore_index=True)\n    \ny = df['default'].values  # наш таргет\nX = df.drop(['default'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:37.745449Z","iopub.execute_input":"2022-02-23T13:56:37.745854Z","iopub.status.idle":"2022-02-23T13:56:37.790994Z","shell.execute_reply.started":"2022-02-23T13:56:37.745817Z","shell.execute_reply":"2022-02-23T13:56:37.790275Z"},"trusted":true},"execution_count":730,"outputs":[]},{"cell_type":"code","source":"# Воспользуемся специальной функцией train_test_split для разбивки тестовых данных\nfrom sklearn.model_selection import train_test_split\n\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:37.792171Z","iopub.execute_input":"2022-02-23T13:56:37.792434Z","iopub.status.idle":"2022-02-23T13:56:37.801138Z","shell.execute_reply.started":"2022-02-23T13:56:37.792404Z","shell.execute_reply":"2022-02-23T13:56:37.800590Z"},"trusted":true},"execution_count":731,"outputs":[]},{"cell_type":"code","source":"# проверяем\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:37.802059Z","iopub.execute_input":"2022-02-23T13:56:37.802596Z","iopub.status.idle":"2022-02-23T13:56:37.809970Z","shell.execute_reply.started":"2022-02-23T13:56:37.802565Z","shell.execute_reply":"2022-02-23T13:56:37.809334Z"},"trusted":true},"execution_count":732,"outputs":[]},{"cell_type":"code","source":"sns.set_theme(style=\"whitegrid\")\nax = sns.boxplot(data=X_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:37.811172Z","iopub.execute_input":"2022-02-23T13:56:37.811415Z","iopub.status.idle":"2022-02-23T13:56:38.557059Z","shell.execute_reply.started":"2022-02-23T13:56:37.811378Z","shell.execute_reply":"2022-02-23T13:56:38.556338Z"},"trusted":true},"execution_count":733,"outputs":[]},{"cell_type":"code","source":"# Делаем для уменьшения влияния выбросов\nfrom sklearn.preprocessing import RobustScaler\nscaler = RobustScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:38.558473Z","iopub.execute_input":"2022-02-23T13:56:38.558737Z","iopub.status.idle":"2022-02-23T13:56:38.580860Z","shell.execute_reply.started":"2022-02-23T13:56:38.558705Z","shell.execute_reply":"2022-02-23T13:56:38.579697Z"},"trusted":true},"execution_count":734,"outputs":[]},{"cell_type":"code","source":"# делаем регуляризацию для уменьшения переобучения модели\nfrom sklearn.preprocessing import Normalizer\nnormal = Normalizer(norm='l1')\nX_train = normal.fit_transform(X_train)\nX_test = normal.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:38.582378Z","iopub.execute_input":"2022-02-23T13:56:38.582817Z","iopub.status.idle":"2022-02-23T13:56:38.589684Z","shell.execute_reply.started":"2022-02-23T13:56:38.582780Z","shell.execute_reply":"2022-02-23T13:56:38.589034Z"},"trusted":true},"execution_count":735,"outputs":[]},{"cell_type":"code","source":"ax = sns.boxplot(data=X_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:38.590781Z","iopub.execute_input":"2022-02-23T13:56:38.591104Z","iopub.status.idle":"2022-02-23T13:56:39.265199Z","shell.execute_reply.started":"2022-02-23T13:56:38.591069Z","shell.execute_reply":"2022-02-23T13:56:39.264610Z"},"trusted":true},"execution_count":736,"outputs":[]},{"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.linear_model import LogisticRegression # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:39.266633Z","iopub.execute_input":"2022-02-23T13:56:39.266841Z","iopub.status.idle":"2022-02-23T13:56:39.270443Z","shell.execute_reply.started":"2022-02-23T13:56:39.266812Z","shell.execute_reply":"2022-02-23T13:56:39.269871Z"},"trusted":true},"execution_count":737,"outputs":[]},{"cell_type":"code","source":"logreg = LogisticRegression(solver='liblinear', C = 0.1, max_iter=1000)\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:39.271618Z","iopub.execute_input":"2022-02-23T13:56:39.271828Z","iopub.status.idle":"2022-02-23T13:56:39.321604Z","shell.execute_reply.started":"2022-02-23T13:56:39.271800Z","shell.execute_reply":"2022-02-23T13:56:39.320597Z"},"trusted":true},"execution_count":738,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nclassification_report = classification_report(y_test, y_pred)\nprint(classification_report)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:39.323118Z","iopub.execute_input":"2022-02-23T13:56:39.323820Z","iopub.status.idle":"2022-02-23T13:56:39.339817Z","shell.execute_reply.started":"2022-02-23T13:56:39.323771Z","shell.execute_reply":"2022-02-23T13:56:39.338513Z"},"trusted":true},"execution_count":739,"outputs":[]},{"cell_type":"markdown","source":"Метрики полученные при выравниивании долей класса путем n-раз добавления класса меньшинства\n\n                precision    recall  f1-score   support\n\n           0       0.66      0.67      0.67     13022\n           1       0.67      0.65      0.66     12985\n\n    accuracy                           0.66     26007\n   macro avg       0.66      0.66      0.66     26007\nweighted avg       0.66      0.66      0.66     26007","metadata":{}},{"cell_type":"markdown","source":"Метрики полученые после выравнивания долей классов путем обрезки доминирующего\n\n                   precision    recall  f1-score   support\n\n           0       0.68      0.69      0.68      1887\n           1       0.68      0.66      0.67      1862\n\n    accuracy                           0.68      3749\n   macro avg       0.68      0.68      0.68      3749\nweighted avg       0.68      0.68      0.68      3749","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Первоначально полученные метрики\n\nprecision    recall  f1-score   support\n\n           0       0.88      1.00      0.93     12933\n           1       0.50      0.00      0.00      1827\n\n    accuracy                           0.88     14760\n   macro avg       0.69      0.50      0.47     14760\nweighted avg       0.83      0.88      0.82     14760","metadata":{}},{"cell_type":"code","source":"# Выводы: \n# 1. Лучшие результаты метрики получились при усечении доминирующего класса\n# 2. RobustScaler и регуляризация улучшают метрики\n# 3. Подбор гиперпараметров пробовал подбирать вручную, C = 0.1 дало улучшение метрик\n","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:39.341259Z","iopub.execute_input":"2022-02-23T13:56:39.342082Z","iopub.status.idle":"2022-02-23T13:56:39.373895Z","shell.execute_reply.started":"2022-02-23T13:56:39.342034Z","shell.execute_reply":"2022-02-23T13:56:39.373115Z"},"trusted":true},"execution_count":740,"outputs":[]},{"cell_type":"code","source":"# Делаем RobustScaler и нормализацию на всех данных\nscaler_X = RobustScaler()\nX = scaler_X.fit_transform(X)\n\nnormal_X = Normalizer(norm='l1')\nX = normal_X.fit_transform(X)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:39.375093Z","iopub.execute_input":"2022-02-23T13:56:39.375816Z","iopub.status.idle":"2022-02-23T13:56:39.406369Z","shell.execute_reply.started":"2022-02-23T13:56:39.375773Z","shell.execute_reply":"2022-02-23T13:56:39.405567Z"},"trusted":true},"execution_count":741,"outputs":[]},{"cell_type":"code","source":"# если качество нас устраивает, обучаем финальную модель на всех обучающи данных\nlogreg_final = LogisticRegression(solver='liblinear', C = 0.1, max_iter=1000)\nlogreg_final.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:39.416441Z","iopub.execute_input":"2022-02-23T13:56:39.417440Z","iopub.status.idle":"2022-02-23T13:56:39.483121Z","shell.execute_reply.started":"2022-02-23T13:56:39.417400Z","shell.execute_reply":"2022-02-23T13:56:39.482369Z"},"trusted":true},"execution_count":743,"outputs":[]},{"cell_type":"code","source":"predict_submission = logreg_final.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:39.484598Z","iopub.execute_input":"2022-02-23T13:56:39.485107Z","iopub.status.idle":"2022-02-23T13:56:39.493529Z","shell.execute_reply.started":"2022-02-23T13:56:39.485062Z","shell.execute_reply":"2022-02-23T13:56:39.492885Z"},"trusted":true},"execution_count":744,"outputs":[]},{"cell_type":"code","source":"sample_submission['default'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:39.495064Z","iopub.execute_input":"2022-02-23T13:56:39.495568Z","iopub.status.idle":"2022-02-23T13:56:39.576990Z","shell.execute_reply.started":"2022-02-23T13:56:39.495507Z","shell.execute_reply":"2022-02-23T13:56:39.576283Z"},"trusted":true},"execution_count":745,"outputs":[]},{"cell_type":"code","source":"# Вот тут случилась непонятная вещь с которой я так и не смог разобраться. \n# При обучении модели на всех обучающих данных модель перестала нормально предсказывать\n# произошло это после того как полных обучающих данных я применил RobustScaler и Normalizer\n# Нужна помощь!","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:39.578508Z","iopub.execute_input":"2022-02-23T13:56:39.578990Z","iopub.status.idle":"2022-02-23T13:56:39.597846Z","shell.execute_reply.started":"2022-02-23T13:56:39.578949Z","shell.execute_reply":"2022-02-23T13:56:39.597098Z"},"trusted":true},"execution_count":746,"outputs":[]},{"cell_type":"code","source":"!kaggle competitions submit -c sf-scoring -f ssubmission.csv -m \"Ilya Galuzin\"\n# !kaggle competitions submit your-competition-name -f submission.csv -m 'My submission message'","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:56:39.599288Z","iopub.execute_input":"2022-02-23T13:56:39.599779Z","iopub.status.idle":"2022-02-23T13:56:40.201056Z","shell.execute_reply.started":"2022-02-23T13:56:39.599739Z","shell.execute_reply":"2022-02-23T13:56:40.200128Z"},"trusted":true},"execution_count":747,"outputs":[]}]}